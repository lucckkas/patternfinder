\section{Resultados experimentales}

Para evaluar el rendimiento de la implementación paralela frente a la secuencial, se ejecutaron benchmarks exhaustivos con secuencias aleatorias de longitud creciente. Las pruebas se realizaron en un sistema con procesador 12 núcleos lógicos utilizando secuencias generadas aleatoriamente con alfabeto de aminoácidos estándar.

\subsection{Metodología}

Se compararon ambas implementaciones (secuencial y paralela) con secuencias de longitud 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180 y 200 caracteres. Para cada longitud se ejecutaron múltiples iteraciones midiendo:

\begin{itemize}
    \item Tiempo de construcción de la tabla de programación dinámica (DP Table)
    \item Tiempo de backtracking para recuperar todas las LCS
    \item Tiempo total de ejecución
    \item Número de subsecuencias comunes más largas encontradas
\end{itemize}

La Tabla~\ref{tab:benchmark_summary} presenta un resumen de los resultados para longitudes seleccionadas:

\begin{table}[H]
    \centering
    \caption[Resumen de resultados experimentales]{Resumen de resultados experimentales para longitudes seleccionadas. Los tiempos están expresados en milisegundos para longitudes $\leq$ 100 y en segundos para longitudes mayores.}
    \label{tab:benchmark_summary}
    \begin{tabular}{|r|r|r|r|r|}
        \hline
        \textbf{Longitud} & \textbf{Seq (ms)} & \textbf{Par (ms)} & \textbf{Speedup} & \textbf{\# LCS} \\ \hline
        20                & 0.20              & 0.93              & 0.22x            & 4               \\ \hline
        50                & 0.30              & 2.20              & 0.14x            & 11              \\ \hline
        100               & 4.52              & 27.27             & 0.17x            & 179             \\ \hline
        120               & 23.23             & 121.13            & 0.19x            & 784             \\ \hline
        140               & 110.43            & 459.60            & 0.24x            & 3,012           \\ \hline
        160               & 239.15            & 1121.17           & 0.21x            & 6,024           \\ \hline
        180               & 2.13 s            & 6.03 s            & 0.35x            & 33,132          \\ \hline
        200               & 12.66 s           & 44.96 s           & 0.28x            & 186,744         \\ \hline
    \end{tabular}
\end{table}

\subsection{Análisis de tiempos de ejecución}

La Figura~\ref{fig:execution_time} muestra la comparación de tiempos de ejecución entre ambas implementaciones. Se observa que el tiempo de ejecución crece exponencialmente con la longitud de las secuencias, alcanzando aproximadamente 13 segundos para la versión secuencial y 45 segundos para la versión paralela en secuencias de longitud 200.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/execution_time.png}
    \caption[Resultados: Tiempos de ejecución secuencial vs paralelo]{Comparación de tiempos de ejecución totales entre las implementaciones secuencial y paralela. La escala logarítmica evidencia el crecimiento exponencial del tiempo con la longitud de las secuencias. En todos los casos evaluados, la versión secuencial presenta menores tiempos de ejecución.}
    \label{fig:execution_time}
\end{figure}

Un hallazgo inesperado es que la implementación secuencial resulta consistentemente más rápida que la paralela en todos los tamaños evaluados. Este comportamiento se explica por el overhead asociado a la creación y sincronización de goroutines, que supera el beneficio de la paralelización para estos tamaños de problema.

\subsection{Speedup y eficiencia}

El speedup, definido como la razón entre el tiempo secuencial y el tiempo paralelo, permite cuantificar la mejora (o degradación) de rendimiento. Un speedup mayor a 1.0 indica que la versión paralela es más rápida, mientras que valores menores a 1.0 indican que la versión secuencial tiene mejor rendimiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/speedup.png}
    \caption[Resultados: Speedup de la versión paralela]{Speedup de la versión paralela respecto a la secuencial. Todos los valores se encuentran por debajo de 1.0, indicando que la implementación secuencial es más eficiente. El speedup promedio observado es de 0.17x, lo que significa que la versión paralela es aproximadamente 6 veces más lenta. La línea punteada roja marca el punto de equilibrio (speedup = 1.0).}
    \label{fig:speedup}
\end{figure}

Como se aprecia en la Figura~\ref{fig:speedup}, el speedup promedio es de 0.17x, significativamente inferior a 1.0. Esto implica que la versión paralela es aproximadamente 6 veces más lenta que la secuencial para estas secuencias. Se observa una ligera tendencia al alza del speedup conforme aumenta la longitud, alcanzando 0.31x para secuencias de longitud 180-200, lo que sugiere que el beneficio de la paralelización podría manifestarse con secuencias aún más largas.

\subsection{Análisis por componente}

Para comprender mejor dónde se concentra el costo computacional, se analizaron por separado los dos componentes principales del algoritmo: la construcción de la tabla DP y el backtracking.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/components.png}
    \caption[Resultados: Análisis por componentes (DP y Backtracking)]{Comparación de tiempos por componente. Izquierda: construcción de la tabla DP. Derecha: backtracking. El backtracking domina el tiempo total de ejecución, especialmente para secuencias largas. La paralelización de la tabla DP introduce un overhead considerable que supera cualquier beneficio potencial.}
    \label{fig:components}
\end{figure}

La Figura~\ref{fig:components} revela que:

\begin{itemize}
    \item \textbf{Construcción de tabla DP}: La versión paralela presenta un overhead significativo (speedup promedio de 0.03x), siendo aproximadamente 33 veces más lenta que la secuencial. El costo de crear goroutines para cada celda de la diagonal supera ampliamente el beneficio computacional.

    \item \textbf{Backtracking}: Aunque el speedup es mayor que en la construcción de la tabla (0.21x en promedio), la versión paralela sigue siendo aproximadamente 5 veces más lenta. El cuello de botella reside en la sincronización requerida para el registro de caminos visitados, donde múltiples goroutines deben acceder y modificar estructuras compartidas mediante mutexes.
\end{itemize}

El backtracking domina el tiempo total de ejecución, representando más del 95\% del tiempo para secuencias largas, mientras que la construcción de la tabla DP es relativamente rápida incluso para las secuencias más extensas evaluadas.

\subsection{Crecimiento del espacio de búsqueda}

El número de subsecuencias comunes más largas crece exponencialmente con la longitud de las secuencias, como se muestra en la Figura~\ref{fig:lcs_count}. Este crecimiento exponencial explica por qué el backtracking se convierte en el componente dominante del tiempo de ejecución.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/lcs_count.png}
    \caption[Resultados: Crecimiento exponencial del número de LCS]{Número de subsecuencias comunes más largas encontradas en función de la longitud de las secuencias. Para secuencias de longitud 200, se encontraron más de 186,000 LCS distintas. Este crecimiento exponencial justifica el incremento dramático en los tiempos de ejecución observados.}
    \label{fig:lcs_count}
\end{figure}

Para secuencias de longitud 200, se identificaron 186,744 subsecuencias comunes más largas distintas. Este número masivo de soluciones requiere que el algoritmo de backtracking explore un árbol de búsqueda exponencialmente grande, donde cada nodo representa una decisión sobre qué dirección seguir en la matriz.