\section{Resultados experimentales}

Para evaluar el rendimiento de la implementación paralela frente a la secuencial, se generaron y compararon secuencias aleatorias de longitud creciente. Las pruebas se realizaron en un sistema con procesador 12 núcleos lógicos utilizando secuencias generadas aleatoriamente con alfabeto de aminoácidos estándar. El script utilizado para la generación de secuencias de prueba se detalla en el Anexo~\ref{anexo:generate-sequences}.

\subsection{Metodología}

Se compararon ambas implementaciones (secuencial y paralela) con secuencias de longitud 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180 y 200 caracteres, generadas de forma aleatoria usando una semilla fija (12345 para la primera secuencia y 67890 para la segunda). Para cada longitud se ejecutaron múltiples iteraciones midiendo:

\begin{itemize}
    \item Tiempo de construcción de la tabla de programación dinámica (DP Table);
    \item Tiempo de backtracking para recuperar todas las LCS;
    \item Tiempo total de ejecución;
    \item Número de subsecuencias comunes más largas encontradas;
\end{itemize}

La Tabla~\ref{tab:benchmark_summary} presenta un resumen de los resultados para longitudes seleccionadas. La primera columna indica la longitud de las secuencias, seguida por los tiempos de ejecución en milisegundos para la implementación secuencial y paralela, respectivamente. La columna de speedup muestra la relación entre los tiempos secuencial y paralelo, y la última columna indica el número de subsecuencias comunes más largas encontradas.

\begin{table}[H]
    \centering
    \caption[Resumen de resultados experimentales]{Resumen de resultados experimentales para longitudes seleccionadas. Los tiempos están expresados en milisegundos.}
    \label{tab:benchmark_summary}
    \begin{tabular}{|r|r|r|r|r|}
        \hline
        \textbf{Longitud} & \textbf{Seq (ms)} & \textbf{Par (ms)} & \textbf{Speedup} & \textbf{\# LCS} \\ \hline
        20                & 0.08              & 1.26              & 0.06x            & 4               \\ \hline
        50                & 0.67              & 2.19              & 0.31x            & 11              \\ \hline
        100               & 7.49              & 18.92             & 0.40x            & 179             \\ \hline
        120               & 31.35             & 65.25             & 0.48x            & 784             \\ \hline
        140               & 139.96            & 304.95            & 0.46x            & 3,012           \\ \hline
        160               & 303.72            & 543.32            & 0.56x            & 6,024           \\ \hline
        180               & 2,399.43          & 3,538.08          & 0.68x            & 33,132          \\ \hline
        200               & 13,255.92         & 19,998.31         & 0.66x            & 186,744         \\ \hline
    \end{tabular}
\end{table}

\subsection{Análisis de tiempos de ejecución}

La Figura~\ref{fig:execution_time} muestra la comparación de tiempos de ejecución entre ambas implementaciones. Se observa que el tiempo de ejecución crece exponencialmente con la longitud de las secuencias, alcanzando aproximadamente 13 segundos para la versión secuencial y 20 segundos para la versión paralela en secuencias de longitud 200.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/execution_time.png}
    \caption[Resultados: Tiempos de ejecución secuencial vs paralelo]{Comparación de tiempos de ejecución totales entre las implementaciones secuencial y paralela. La escala logarítmica evidencia el crecimiento exponencial del tiempo con la longitud de las secuencias. En todos los casos evaluados, la versión secuencial presenta menores tiempos de ejecución.}
    \label{fig:execution_time}
\end{figure}

Un hallazgo inesperado es que la implementación secuencial resulta consistentemente más rápida que la paralela en todos los tamaños evaluados. Este comportamiento se explica por el overhead asociado a la creación y sincronización de goroutines, que supera el beneficio de la paralelización para estos tamaños de problema.

\subsection{Speedup y eficiencia}

El speedup, definido como la razón entre el tiempo secuencial y el tiempo paralelo ($\frac{T_{sec}}{T_{par}}$), permite cuantificar la mejora (o degradación) de rendimiento. Un speedup mayor a 1.0 indica que la versión paralela es más rápida, mientras que valores menores a 1.0 indican que la versión secuencial tiene mejor rendimiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/speedup.png}
    \caption[Resultados: Speedup de la versión paralela]{Speedup de la versión paralela respecto a la secuencial. Todos los valores se encuentran por debajo de 1.0, indicando que la implementación secuencial es más eficiente. El speedup promedio observado es de 0.37x, lo que significa que la versión paralela es aproximadamente 2.7 veces más lenta. La línea punteada roja marca el punto de equilibrio (speedup = 1.0). Aunque se observa una tendencia al alza con secuencias más largas, el speedup sigue siendo inferior a 1.0 en todos los casos evaluados.}
    \label{fig:speedup}
\end{figure}

Como se aprecia en la Figura~\ref{fig:speedup}, el speedup promedio es de 0.37x, significativamente inferior a 1.0. Esto implica que la versión paralela es aproximadamente 2.7 veces más lenta que la secuencial para estas secuencias. Se observa una tendencia al alza del speedup conforme aumenta la longitud, alcanzando 0.67x para secuencias de longitud 180-200, lo que sugiere que el beneficio de la paralelización podría manifestarse con secuencias aún más largas.
\subsection{Análisis por componente}

Para comprender mejor dónde se concentra el costo computacional, se analizaron por separado los dos componentes principales del algoritmo: la construcción de la tabla DP y el backtracking.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/components.png}
    \caption[Resultados: Análisis por componentes (DP y Backtracking)]{Comparación de tiempos por componente. Izquierda: construcción de la tabla DP. Derecha: backtracking. El backtracking domina gran parte del tiempo de ejecución, especialmente para secuencias largas.}
    \label{fig:components}
\end{figure}

La Figura~\ref{fig:components} revela que:

\begin{itemize}
    \item \textbf{Construcción de tabla DP}: La versión paralela presenta una sobrecarga significativa, siendo consistentemente más lenta que la secuencial en todo el rango evaluado. Para secuencias pequeñas (longitud 20-50), la sobrecarga de creación y sincronización de goroutines domina completamente, resultando en tiempos 30-50 veces mayores. Sin embargo, para secuencias largas (180-260), esta sobrecarga se estabiliza en el rango de 10-20ms mientras que la versión secuencial se mantiene bajo 0.5ms, indicando que el costo de paralelización es constante pero el beneficio computacional sigue siendo insuficiente.

    \item \textbf{Backtracking}: Este componente muestra un comportamiento más favorable a la paralelización. Para secuencias pequeñas, la versión paralela es más lenta (speedup de 0.26x-0.37x), pero conforme aumenta la longitud, el speedup mejora progresivamente hasta alcanzar 0.66x-0.74x para secuencias de 180-260 caracteres. Esto sugiere que el beneficio de explorar múltiples caminos simultánea-mente comienza a compensar parcialmente la sobrecarga de sincronización cuando el espacio de búsqueda se vuelve suficientemente grande.
\end{itemize}

El backtracking domina el tiempo total de ejecución, representando más del 95\% del tiempo para secuencias largas, mientras que la construcción de la tabla DP es relativamente rápida incluso para las secuencias más extensas evaluadas.

\subsection{Crecimiento del espacio de búsqueda}

El número de subsecuencias comunes más largas crece exponencialmente con la longitud de las secuencias, como se muestra en la Figura~\ref{fig:lcs_count}. Este crecimiento exponencial explica por qué el backtracking se convierte en el componente dominante del tiempo de ejecución.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/Benchmark/lcs_count.png}
    \caption[Resultados: Crecimiento exponencial del número de LCS]{Número de subsecuencias comunes más largas encontradas en función de la longitud de las secuencias. Para secuencias de longitud 200, se encontraron más de 186,000 LCS distintas. Este crecimiento exponencial justifica el incremento dramático en los tiempos de ejecución observados.}
    \label{fig:lcs_count}
\end{figure}

Para secuencias de longitud 200, se identificaron 186,744 subsecuencias comunes más largas distintas. Este número masivo de soluciones requiere que el algoritmo de backtracking explore un árbol de búsqueda exponencialmente grande, donde cada nodo representa una decisión sobre qué dirección seguir en la matriz.