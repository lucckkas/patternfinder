# Resumen de Benchmark: Secuencial vs Paralelo

## ğŸ“Š Resultados Principales

Se ejecutaron benchmarks comparando las versiones **secuencial** y **paralela** del algoritmo LCS con secuencias aleatorias de longitud creciente (20, 30, 40, ..., 200).

### Hallazgos Clave

-   âœ— **La versiÃ³n secuencial es mÃ¡s rÃ¡pida** en todos los casos probados
-   ğŸ“‰ Speedup promedio: **0.17x** (paralelo es ~6x mÃ¡s lento)
-   ğŸ” El backtracking es el componente dominante en tiempo de ejecuciÃ³n
-   ğŸ“ˆ El nÃºmero de LCS encontradas crece exponencialmente con la longitud

## ğŸ“ˆ EstadÃ­sticas Detalladas

### Speedup por Componente

-   **DP Table**: 0.03x (paralelo es ~33x mÃ¡s lento)
-   **Backtracking**: 0.21x (paralelo es ~5x mÃ¡s lento)
-   **Total**: 0.17x (paralelo es ~6x mÃ¡s lento)

### Ejemplos de Tiempos

| Longitud | Secuencial | Paralelo | Speedup | LCS# |
| -------- | ---------- | -------- | ------- | ---- |
| 20       | 0.05 ms    | 0.48 ms  | 0.11x   | 4    |
| 50       | 0.21 ms    | 1.75 ms  | 0.12x   | 11   |
| 100      | 4.58 ms    | 25.90 ms | 0.18x   | 179  |
| 200      | 15.3 s     | 50.0 s   | 0.31x   | 186k |

## ğŸ” AnÃ¡lisis

### Â¿Por quÃ© la versiÃ³n paralela es mÃ¡s lenta?

1. **Overhead de goroutines**: Crear y gestionar goroutines tiene un costo significativo
2. **SincronizaciÃ³n**: Los mutexes para el registro de caminos visitados aÃ±aden latencia
3. **Naturaleza del problema**: El backtracking con detecciÃ³n de caminos duplicados requiere acceso compartido al estado
4. **Secuencias aleatorias**: Generan muchas bifurcaciones que requieren sincronizaciÃ³n constante

### Componente mÃ¡s costoso

El **backtracking** domina el tiempo de ejecuciÃ³n, representando >95% del tiempo total para secuencias largas. Esto se debe a que:

-   El nÃºmero de caminos crece exponencialmente
-   Cada camino debe verificarse contra el registro de visitados
-   La complejidad en el peor caso es O(2^n)

## ğŸ¯ CuÃ¡ndo usar cada versiÃ³n

### Usar VersiÃ³n Secuencial:

-   âœ… Secuencias pequeÃ±as a medianas (< 200)
-   âœ… Secuencias aleatorias con muchas bifurcaciones
-   âœ… Cuando la latencia es crÃ­tica
-   âœ… Hardware con pocos cores

### Usar VersiÃ³n Paralela:

-   âš ï¸ Secuencias muy grandes (> 500) donde el DP Table es significativo
-   âš ï¸ Secuencias con pocas bifurcaciones
-   âš ï¸ Hardware con muchos cores (16+)
-   âš ï¸ Cuando se procesan mÃºltiples pares de secuencias en paralelo

## ğŸ› ï¸ Archivos Generados

```
benchmark_results/
â”œâ”€â”€ results.csv                    # Datos en formato CSV
â”œâ”€â”€ comparison_detailed.txt        # ComparaciÃ³n detallada
â”œâ”€â”€ benchmark_full.txt             # Benchmarks completos de Go
â”œâ”€â”€ benchmark_dp.txt               # Benchmarks solo DP Table
â”œâ”€â”€ benchmark_bt.txt               # Benchmarks solo Backtracking
â”œâ”€â”€ execution_time.png             # GrÃ¡fico de tiempos (si se generÃ³)
â”œâ”€â”€ speedup.png                    # GrÃ¡fico de speedup (si se generÃ³)
â”œâ”€â”€ components.png                 # GrÃ¡fico de componentes (si se generÃ³)
â””â”€â”€ lcs_count.png                  # GrÃ¡fico de nÃºmero de LCS (si se generÃ³)
```

## ğŸš€ CÃ³mo Ejecutar

### EjecuciÃ³n rÃ¡pida (solo datos CSV):

```bash
go run cmd/benchmark/main.go
python3 analyze_results.py
```

### EjecuciÃ³n completa con benchmarks de Go:

```bash
./run_benchmark.sh
```

### Generar grÃ¡ficos (requiere matplotlib):

```bash
pip install pandas matplotlib
python3 generate_plots.py
```

## ğŸ“ Conclusiones

1. **La paralelizaciÃ³n no siempre mejora el rendimiento**: El overhead puede superar los beneficios
2. **La detecciÃ³n de caminos duplicados requiere sincronizaciÃ³n**: Esto aÃ±ade latencia en la versiÃ³n paralela
3. **El backtracking es inherentemente secuencial**: Los caminos dependen unos de otros
4. **La implementaciÃ³n secuencial es mÃ¡s simple y eficiente**: Para este caso de uso especÃ­fico

### RecomendaciÃ³n

Para el caso de uso actual (secuencias de proteÃ­nas y ligandos), se recomienda:

-   Usar la **versiÃ³n secuencial** para el procesamiento individual de pares
-   Considerar **paralelizar a nivel superior**: procesar mÃºltiples pares de secuencias en paralelo
-   Optimizar el **algoritmo de backtracking** antes de paralelizar

## ğŸ“š Referencias

-   CÃ³digo fuente: `internal/lcs/lcs.go`
-   Tests: `test/benchmark_test.go`
-   DocumentaciÃ³n: `BENCHMARK_README.md`
